# ğŸŒ Web Scraping and Chatbot Integration App

This project is a **Flask-based web application** that allows users to scrape website content, store it in a **PostgreSQL** database, and interact with the scraped data through an intelligent **chatbot interface**.  

It combines web scraping, structured data storage, and natural language querying for a complete web intelligence workflow.

---

## ğŸš€ Features

- ğŸ•¸ï¸ **Web Scraping:** Extracts text, links, images, videos, and document URLs from any webpage.
- ğŸ’¾ **Database Integration:** Stores structured scraped data into a PostgreSQL database.
- ğŸ’¬ **Chatbot Interface:** Interact with the stored data using simple queries.
- ğŸ“‚ **Selective Scraping:** Choose which content categories to scrape (Text, Links, Images, Videos, Documents).
- ğŸ§  **Data Normalization:** Prepares and chunks scraped data for easier processing and LLM parsing.
- ğŸ§© **Modular Architecture:** Core scraping logic is abstracted in the `doc.py` module.

---

## ğŸ§° Tech Stack

| Component | Technology |
|------------|-------------|
| **Backend Framework** | Flask |
| **Database** | PostgreSQL |
| **Language** | Python 3.8+ |
| **Libraries** | requests, BeautifulSoup, psycopg2, Flask, JSON, etc. |

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/<your-username>/web-scraper-chatbot.git
cd web-scraper-chatbot
```

### 2ï¸âƒ£ Create a virtual environment (recommended)
```bash
python -m venv venv
source venv/bin/activate      # For Linux/Mac
venv\Scripts\activate         # For Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

Example `requirements.txt`:
```
Flask
psycopg2
requests
beautifulsoup4
```
*(Include other libraries you use inside `doc.py` if needed.)*

---

## ğŸ—„ï¸ Database Setup

1. Open PostgreSQL and create a new database:
   ```sql
   CREATE DATABASE your_database_name;
   ```

2. Create a table for storing scraped data:
   ```sql
   CREATE TABLE scraped_data (
       url TEXT PRIMARY KEY,
       content JSONB
   );
   ```

3. Update the following credentials in your Python file:
   ```python
   hostname = 'localhost'
   database = 'your_database_name'
   username = 'postgres'
   pwd = 'your_password'
   port_id = 5432
   ```

---

## ğŸ§© App Structure

```
web-scraper-chatbot/
â”‚
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ doc.py                 # Contains scraping, downloading, and chatbot logic
â”œâ”€â”€ templates/             # HTML templates (home, categories, chatbot pages)
â”‚   â”œâ”€â”€ home.html
â”‚   â”œâ”€â”€ categories.html
â”‚   â””â”€â”€ chatbot.html
â”œâ”€â”€ static/                # (Optional) CSS/JS files for frontend
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸ–¥ï¸ Usage

1. Run the Flask app:
   ```bash
   python app.py
   ```

2. Open your browser and go to:
   ```
   http://127.0.0.1:5000/
   ```

3. Enter a **base URL** to scrape.

4. Select which **categories** you want to extract:
   - âœ… Text
   - âœ… Links
   - âœ… Images
   - âœ… Videos
   - âœ… Documents

5. Once scraped, interact with the **chatbot** to query the data.  
   Example:
   > â€œSummarize the content from this website.â€  
   > â€œList all image links.â€  
   > â€œFind PDF documents available on the page.â€

---

## ğŸ’¾ Data Normalization for LLMs

The app automatically:
- Splits long text into smaller chunks.
- Limits the number of stored images/videos (to improve performance).
- Converts all content into a clean JSON format before saving to PostgreSQL.

---

## ğŸ’¬ Chatbot Querying

The chatbot retrieves stored data from the database and processes user queries using the `handle_chatbot_query()` function in `doc.py`.  
It allows natural language search and summarization on top of the scraped dataset.

---

## ğŸ”’ Error Handling

- Handles invalid URLs or pages without accessible content.
- Updates existing entries in the database if the same URL is scraped again.
- Displays user-friendly messages if no data is found.

---

## ğŸ”® Future Enhancements

- ğŸ¤– Integrate GPT-based LLM for advanced query responses.
- ğŸ“Š Add a dashboard for analyzing scraped data.
- ğŸŒ Support batch scraping of multiple URLs.
- ğŸ’¬ Enhance chatbot context understanding.

---

## ğŸ¤ Contributing

Pull requests are welcome!  
If you'd like to improve scraping speed, add AI enhancements, or improve the chatbot, open an issue or submit a PR.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€“ see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Utkarsh Tripathi**  
ğŸ”— [GitHub](https://github.com/<your-username>) â€¢ âœ‰ï¸ [Email](mailto:<your-email>)
